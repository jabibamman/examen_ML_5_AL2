{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MachineLearnia/Python-Machine-Learning/blob/master/24%20-%20Sklearn%20%3A%20Apprentissage%20Non-supervis%C3%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:43.564788Z",
     "start_time": "2025-06-25T13:52:43.462361Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6w1Nit4_Fk5L"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway, kruskal, chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m raw_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput/housing.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m raw_data.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developpement/Python/examen_ML_5_AL2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developpement/Python/examen_ML_5_AL2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developpement/Python/examen_ML_5_AL2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developpement/Python/examen_ML_5_AL2/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developpement/Python/examen_ML_5_AL2/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'input/housing.csv'"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"input/housing.csv\", sep=\"\\t\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringcols = raw_data.select_dtypes(include=\"object\").columns\n",
    "print(stringcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_conv = raw_data.copy()\n",
    "raw_data_conv[stringcols] = raw_data_conv[stringcols].astype(str)\n",
    "raw_data_conv[stringcols] = raw_data_conv[stringcols].astype('string')\n",
    "raw_data_conv[stringcols] = raw_data_conv[stringcols].replace({pd.NA: np.nan})\n",
    "raw_data_conv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de valeurs manquantes\n",
    "print(raw_data_conv.isnull().sum().sort_values(ascending=False))\n",
    "# Proportion de valeurs manquantes\n",
    "raw_data_conv.isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_median =  raw_data_conv[\"total_bedrooms\"].fillna(raw_data_conv[\"total_bedrooms\"].median())\n",
    "data_median.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJHL6LQpG6np"
   },
   "source": [
    "# 24/30 Apprentissage Non-Supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:43.586374Z",
     "start_time": "2025-06-25T13:52:43.577901Z"
    }
   },
   "outputs": [],
   "source": [
    "def compare_clusters_full_with_total(df, cluster_col,\n",
    "                                      numeric_vars=None,\n",
    "                                        cat_vars=None,\n",
    "                                          test_type=\"anova\"):\n",
    "    df_copy = df.copy()\n",
    "    numeric_results = []\n",
    "    categorical_results = []\n",
    "\n",
    "    # Convertir cluster_col en chaînes\n",
    "    df_copy[cluster_col] = df_copy[cluster_col].astype(str)\n",
    "    unique_clusters = df_copy[cluster_col].unique().tolist()\n",
    "\n",
    "    # Palette couleurs\n",
    "    palette = sns.color_palette(\"Set2\", n_colors=len(unique_clusters))\n",
    "    palette_dict = {str(c): palette[i] for i, c in enumerate(unique_clusters)}\n",
    "    palette_dict[\"Total\"] = \"blue\"\n",
    "\n",
    "    if numeric_vars:\n",
    "        print(\"\\n=== Analyse des variables numériques ===\\n\")\n",
    "        for var in numeric_vars:\n",
    "            # Ajout ligne \"Total\"\n",
    "            total_df = df_copy[[var]].copy()\n",
    "            total_df[cluster_col] = \"Total\"\n",
    "            df_with_total = pd.concat([df_copy[[cluster_col, var]], total_df], axis=0)\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.boxplot(data=df_with_total, x=cluster_col, y=var, hue=cluster_col, palette=palette_dict, legend=False)\n",
    "\n",
    "            # sns.boxplot(data=df_with_total, x=cluster_col, y=var, palette=palette_dict)\n",
    "            plt.title(f'Distribution de {var} par cluster (incluant Total)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Statistiques descriptives AVEC total\n",
    "            print(f\"\\n Statistiques pour '{var}' :\")\n",
    "            desc = df_with_total.groupby(cluster_col)[var].describe()\n",
    "            print(desc)\n",
    "\n",
    "            # Test statistique sur vrais clusters\n",
    "            cluster_only = df_copy[df_copy[cluster_col] != \"Total\"]\n",
    "            grouped_data = [group[var].dropna() for name, group in cluster_only.groupby(cluster_col)]\n",
    "            if test_type == \"anova\":\n",
    "                stat, p = f_oneway(*grouped_data)\n",
    "                test_name = \"ANOVA\"\n",
    "            else:\n",
    "                stat, p = kruskal(*grouped_data)\n",
    "                test_name = \"Kruskal-Wallis\"\n",
    "\n",
    "            numeric_results.append({\n",
    "                \"variable\": var,\n",
    "                \"test\": test_name,\n",
    "                \"stat\": stat,\n",
    "                \"p_value\": p\n",
    "            })\n",
    "\n",
    "    if cat_vars:\n",
    "        print(\"\\n=== Analyse des variables catégorielles ===\\n\")\n",
    "        for var in cat_vars:\n",
    "            # Ajout ligne \"Total\"\n",
    "            total_row = pd.DataFrame({cluster_col: [\"Total\"], var: [None]})\n",
    "            df_cat = pd.concat([df_copy[[cluster_col, var]], total_row], axis=0)\n",
    "\n",
    "            # Tableau croisé AVEC total\n",
    "            contingency_table = pd.crosstab(df_copy[cluster_col], df_copy[var], dropna=False)\n",
    "            print(f\"\\n Tableau croisé pour '{var}' (sans Total dans test) :\")\n",
    "            print(contingency_table)\n",
    "\n",
    "            # Heatmap\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Tableau croisé: {var} vs {cluster_col}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Test du chi² sur vrais clusters uniquement\n",
    "            cat_only = df_copy[df_copy[cluster_col] != \"Total\"]\n",
    "            contingency = pd.crosstab(cat_only[cluster_col], cat_only[var], dropna=False)\n",
    "            chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "            categorical_results.append({\n",
    "                \"variable\": var,\n",
    "                \"test\": \"Chi2\",\n",
    "                \"stat\": chi2,\n",
    "                \"p_value\": p\n",
    "            })\n",
    "\n",
    "    if numeric_results:\n",
    "        print(\"\\n Résumé des tests numériques :\")\n",
    "        display(pd.DataFrame(numeric_results).sort_values(\"p_value\"))\n",
    "\n",
    "    if categorical_results:\n",
    "        print(\"\\n Résumé des tests catégoriels :\")\n",
    "        display(pd.DataFrame(categorical_results).sort_values(\"p_value\"))\n",
    "\n",
    "    return pd.DataFrame(numeric_results), pd.DataFrame(categorical_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbMWrDTWHOMD"
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:43.813537Z",
     "start_time": "2025-06-25T13:52:43.677224Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "ykSChVc_G5_k",
    "outputId": "84bb8979-0662-45f3-d51d-03f36940b1dc"
   },
   "outputs": [],
   "source": [
    "# Génération de données \n",
    "X, y = make_blobs(n_samples=100, centers=3, cluster_std=0.4, random_state=0)\n",
    "plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.011707Z",
     "start_time": "2025-06-25T13:52:43.839170Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.059444Z",
     "start_time": "2025-06-25T13:52:44.027985Z"
    }
   },
   "outputs": [],
   "source": [
    "# création du modèle\n",
    "model_kmeans = KMeans(n_clusters=4)\n",
    "model_kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catégorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.105398Z",
     "start_time": "2025-06-25T13:52:44.093754Z"
    }
   },
   "outputs": [],
   "source": [
    "X_km = X.copy()\n",
    "X_km = pd.DataFrame(X_km)\n",
    "clustering_labels_km = model_kmeans.fit_predict(X)\n",
    "X_km['clusters'] = clustering_labels_km\n",
    "X_km['clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.195936Z",
     "start_time": "2025-06-25T13:52:44.189810Z"
    }
   },
   "outputs": [],
   "source": [
    "X_km.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.299840Z",
     "start_time": "2025-06-25T13:52:44.297248Z"
    }
   },
   "outputs": [],
   "source": [
    "# connaitre le nombre de cluster\n",
    "model_kmeans.n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.640887Z",
     "start_time": "2025-06-25T13:52:44.507133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualisation des clusters\n",
    "plt.scatter(X[:,0], X[:,1], c = clustering_labels_km)\n",
    "plt.scatter(model_kmeans.cluster_centers_[:,0], model_kmeans.cluster_centers_[:,1], c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.735484Z",
     "start_time": "2025-06-25T13:52:44.730366Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.silhouette_score(X_km, X_km['clusters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cALI-5h2Hc7v"
   },
   "source": [
    "#### Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:44.890505Z",
     "start_time": "2025-06-25T13:52:44.858776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recherche du k optimal par la méthode du coude\n",
    "inertia = []\n",
    "K_range = range(1, 20)\n",
    "for k in K_range:\n",
    "    model = KMeans(n_clusters=k).fit(X)\n",
    "    inertia.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.065126Z",
     "start_time": "2025-06-25T13:52:44.930364Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "MIBd3MvvHNFi",
    "outputId": "71be8a80-8ad0-4922-eab0-207a08699fa2"
   },
   "outputs": [],
   "source": [
    "# Visualisation du coude\n",
    "plt.plot(K_range, inertia)\n",
    "plt.xlabel('nombre de clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.480096Z",
     "start_time": "2025-06-25T13:52:45.078295Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_vars = [0, 1]\n",
    "# cat_vars = ['sexe', 'statut_marital']\n",
    "\n",
    "numeric_summary, cat_summary = compare_clusters_full_with_total(\n",
    "    df = X_km,\n",
    "    cluster_col='clusters',\n",
    "    numeric_vars=numeric_vars,\n",
    "    # cat_vars=cat_vars,\n",
    "    test_type='anova'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-yhxJraHiLU"
   },
   "source": [
    "## 2. Detection d'anomalies avec Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.556038Z",
     "start_time": "2025-06-25T13:52:45.523626Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ydb36Yv3Hocs"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.857020Z",
     "start_time": "2025-06-25T13:52:45.674821Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "irVqoD85HX-e",
    "outputId": "c83165e1-742b-4f00-b6b5-17a202a786d9"
   },
   "outputs": [],
   "source": [
    "# Générer les données\n",
    "X, y = make_blobs(n_samples=50, centers=1, cluster_std=0.1, random_state=0)\n",
    "X[-1,:] = np.array([2.25, 5])\n",
    "\n",
    "plt.scatter(X[:,0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.965649Z",
     "start_time": "2025-06-25T13:52:45.874629Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "_lXr47YMHpjE",
    "outputId": "2b49bd16-6e94-4cd4-934d-847e03d04da4"
   },
   "outputs": [],
   "source": [
    "# Création du modèle d'isolation Forest\n",
    "\n",
    "model_isofo = IsolationForest(contamination=0.5)\n",
    "\n",
    "anomalies = model_isofo.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:45.986118Z",
     "start_time": "2025-06-25T13:52:45.980148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clusters des anomalies\n",
    "clusters_ano = anomalies.predict(X)\n",
    "\n",
    "clusters_ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:46.053806Z",
     "start_time": "2025-06-25T13:52:46.046910Z"
    }
   },
   "outputs": [],
   "source": [
    "X_ano = X.copy()\n",
    "X_ano = pd.DataFrame(X_ano)\n",
    "X_ano['clusters'] = clusters_ano\n",
    "X_ano['clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:46.295965Z",
     "start_time": "2025-06-25T13:52:46.131490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualisation des clusters des anomalies\n",
    "plt.scatter(X_ano[0], X_ano[1], c=clusters_ano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:46.408099Z",
     "start_time": "2025-06-25T13:52:46.401891Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.silhouette_score(X_ano, X_ano['clusters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.037451Z",
     "start_time": "2025-06-25T13:52:46.504754Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_vars = [0, 1]\n",
    "# cat_vars = ['sexe', 'statut_marital']\n",
    "\n",
    "numeric_summary, cat_summary = compare_clusters_full_with_total(\n",
    "    df = X_ano,\n",
    "    cluster_col='clusters',\n",
    "    numeric_vars=numeric_vars,\n",
    "    # cat_vars=cat_vars,\n",
    "    test_type='anova'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCvustw9NsNT"
   },
   "source": [
    "## 3. DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.072550Z",
     "start_time": "2025-06-25T13:52:47.069948Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.298609Z",
     "start_time": "2025-06-25T13:52:47.289722Z"
    }
   },
   "outputs": [],
   "source": [
    "db_model = DBSCAN(eps=0.5, min_samples=4)\n",
    "\n",
    "# modelisation\n",
    "\n",
    "clustering = db_model.fit(X)\n",
    "\n",
    "clustering_labels = db_model.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catégorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.389362Z",
     "start_time": "2025-06-25T13:52:47.379420Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_db = X.copy()\n",
    "X_db = pd.DataFrame(X_db)\n",
    "X_db['clusters'] = clustering_labels\n",
    "#clusters_db = pd.DataFrame({'clusters':clustering.labels_})\n",
    "X_db['clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.730398Z",
     "start_time": "2025-06-25T13:52:47.532259Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_db[0], X_db[1], c=clustering.labels_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:47.833911Z",
     "start_time": "2025-06-25T13:52:47.828140Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.silhouette_score(X_db, X_db['clusters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T13:52:48.349701Z",
     "start_time": "2025-06-25T13:52:47.925095Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_vars = [0, 1]\n",
    "# cat_vars = ['sexe', 'statut_marital']\n",
    "\n",
    "numeric_summary, cat_summary = compare_clusters_full_with_total(\n",
    "    df = X_db,\n",
    "    cluster_col='clusters',\n",
    "    numeric_vars=numeric_vars,\n",
    "    # cat_vars=cat_vars,\n",
    "    test_type='anova'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMkFPGWyDnOkG15HtfAhlFS",
   "include_colab_link": true,
   "name": "Untitled7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
